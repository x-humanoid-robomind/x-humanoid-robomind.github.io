{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install opencv-python\n",
    "!pip install h5py\n",
    "!pip install imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import argparse\n",
    "import imageio\n",
    "import h5py\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from IPython.display import Image, display\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReadH5Files():\n",
    "    def __init__(self, robot_infor):\n",
    "        self.camera_names = robot_infor['camera_names']\n",
    "        self.camera_sensors = robot_infor['camera_sensors']\n",
    "        self.arms = robot_infor['arms']\n",
    "        self.robot_infor = robot_infor['controls']\n",
    "\n",
    "    def decoder_image(self, camera_rgb_images, camera_depth_images):\n",
    "        if type(camera_rgb_images[0]) is np.uint8:\n",
    "            rgb = cv2.imdecode(camera_rgb_images, cv2.IMREAD_COLOR)\n",
    "            if camera_depth_images is not None:\n",
    "                depth_array = np.frombuffer(camera_depth_images, dtype=np.uint8)\n",
    "                depth = cv2.imdecode(depth_array, cv2.IMREAD_UNCHANGED)\n",
    "            else:\n",
    "                depth = np.asarray([])\n",
    "            return rgb, depth\n",
    "        else:\n",
    "            rgb_images = []\n",
    "            depth_images = []\n",
    "            for idx, camera_rgb_image in enumerate(camera_rgb_images):\n",
    "                camera_rgb_image = np.array(camera_rgb_image)\n",
    "                # print(f\"camera_rgb_image: {camera_rgb_image.shape}\")\n",
    "                rgb = cv2.imdecode(camera_rgb_image, cv2.IMREAD_COLOR)\n",
    "                if rgb is None:\n",
    "                    rgb = np.frombuffer(camera_rgb_image, dtype=np.uint8)\n",
    "                    if rgb.size == 2764800:\n",
    "                        rgb = rgb.reshape(720, 1280, 3)\n",
    "                    elif rgb.size == 921600:\n",
    "                        rgb = rgb.reshape(480, 640, 3)\n",
    "                if camera_depth_images is not None:\n",
    "                    # print(f\"camera_depth_images shape: {camera_depth_images[idx].shape}\")\n",
    "                    depth_array = np.frombuffer(camera_depth_images[idx], dtype=np.uint8)\n",
    "                    depth = cv2.imdecode(depth_array, cv2.IMREAD_UNCHANGED)\n",
    "                    if depth is None:\n",
    "                        # print(f\"camera_depth_images shape: {camera_depth_images[idx].shape}\")\n",
    "                        depth = np.frombuffer(camera_depth_images[idx], dtype=np.uint8)\n",
    "                        if depth.size == 921600:\n",
    "                            depth = depth.reshape(720, 1280)\n",
    "                        elif depth.size == 307200:\n",
    "                            depth = depth.reshape(480, 640)\n",
    "                            \n",
    "                else:\n",
    "                    depth = np.asarray([])\n",
    "                rgb_images.append(rgb)\n",
    "                depth_images.append(depth)\n",
    "            rgb_images = np.asarray(rgb_images)\n",
    "            depth_images = np.asarray(depth_images)\n",
    "            return rgb_images, depth_images\n",
    "\n",
    "    def execute(self, file_path, camera_frame=None, control_frame=None):\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            is_sim = f.attrs['sim']\n",
    "            is_compress = f.attrs['compress']\n",
    "            is_compress = True\n",
    "            image_dict = defaultdict(dict)\n",
    "            for cam_name in self.camera_names:\n",
    "                if is_compress:\n",
    "                    if camera_frame is not None:\n",
    "                        if len(self.camera_sensors) >= 2:\n",
    "                            decode_rgb, decode_depth = self.decoder_image(\n",
    "                                camera_rgb_images=f['observations'][self.camera_sensors[0]][cam_name][camera_frame],\n",
    "                                    camera_depth_images=f['observations'][self.camera_sensors[1]][cam_name][camera_frame])\n",
    "                        else:\n",
    "                            decode_rgb, decode_depth = self.decoder_image(\n",
    "                                camera_rgb_images=f['observations'][self.camera_sensors[0]][cam_name][camera_frame],\n",
    "                                camera_depth_images=None)\n",
    "                    else:\n",
    "                        if len(self.camera_sensors) >= 2:\n",
    "                            ## print camera_sensors keys and camera_keys if needed for debugging\n",
    "                            # print(f\"camera_sensors keys: {f['observations'].keys()}\")\n",
    "                            # print(f\"camera_keys: {f['observations'][self.camera_sensors[0]].keys()}\")\n",
    "                            rgb_images = f['observations'][self.camera_sensors[0]][cam_name][:]\n",
    "                            depth_images = f['observations'][self.camera_sensors[1]][cam_name][:]\n",
    "                        else:\n",
    "                            rgb_images = f['observations'][self.camera_sensors[0]][cam_name][:]\n",
    "                            depth_images = None\n",
    "                        print(f\"rgb_images: {rgb_images.shape}\")\n",
    "                        print(f\"depth_images: {depth_images.shape if depth_images is not None else 'None'}\")\n",
    "                        decode_rgb, decode_depth = self.decoder_image(camera_rgb_images=rgb_images,camera_depth_images=depth_images)\n",
    "                    \n",
    "                    image_dict[self.camera_sensors[0]][cam_name] = decode_rgb\n",
    "                    if len(self.camera_sensors) >= 2:\n",
    "                        image_dict[self.camera_sensors[1]][cam_name] = decode_depth\n",
    "\n",
    "                else:\n",
    "                    if camera_frame:\n",
    "                        image_dict[self.camera_sensors[0]][cam_name] = f[\n",
    "                            'observations'][self.camera_sensors[0]][cam_name][camera_frame]\n",
    "                        image_dict[self.camera_sensors[1]][cam_name] = f[\n",
    "                            'observations'][self.camera_sensors[1]][cam_name][camera_frame]\n",
    "                    else:\n",
    "                        image_dict[self.camera_sensors[0]][cam_name] = f[\n",
    "                           'observations'][self.camera_sensors[0]][cam_name][:]\n",
    "                        if len(self.camera_sensors) >= 2:\n",
    "                            image_dict[self.camera_sensors[1]][cam_name] = f[\n",
    "                                'observations'][self.camera_sensors[1]][cam_name][:]\n",
    "\n",
    "\n",
    "            control_dict = defaultdict(dict)\n",
    "            for arm_name in self.arms:\n",
    "                for control in self.robot_infor:\n",
    "                    if control_frame:\n",
    "                        control_dict[arm_name][control] = f[arm_name][control][control_frame]\n",
    "                    else:\n",
    "                        control_dict[arm_name][control] = f[arm_name][control][:]\n",
    "            base_dict = defaultdict(dict)\n",
    "        \n",
    "        return image_dict, control_dict, base_dict, is_sim, is_compress\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_dataset_image(cur_embodiments, robot_infor, resolution=RESOLUTION, dataset_dir=\"realworld_data\", env_names=None, save_dir='quick_start_saved_images',episode_num_pertask=2):\n",
    "    read_h5files = ReadH5Files(robot_infor)\n",
    "\n",
    "    \n",
    "    for env_name in env_names:\n",
    "        save_dir = f'{save_dir}/{env_name}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        dataset_root = os.path.join(dataset_dir, env_name, 'success_episodes/train')\n",
    "        cnt = 0\n",
    "        for trajectory_id in sorted(os.listdir(dataset_root))[0:episode_num_pertask]:\n",
    "            for file in os.listdir(os.path.join(dataset_root, trajectory_id, 'data')):\n",
    "                if file.endswith('.hdf5'):\n",
    "                    file_path = os.path.join(dataset_root, trajectory_id, 'data', file)\n",
    "                    break\n",
    "            print('executing ', cnt, 'th trajectory, file_path:', file_path)\n",
    "            cnt += 1\n",
    "            assert os.path.exists(file_path), f'{file_path} does not exist'\n",
    "            image_dict, control_dict, base_dict, _, is_compress = read_h5files.execute(file_path)\n",
    "            action_list = []\n",
    "            for keys in control_dict.keys():\n",
    "                control_list = []\n",
    "                for control_key in control_dict[keys].keys():\n",
    "                    control = control_dict[keys][control_key]\n",
    "                    # in simulation, the control data may not be aligned\n",
    "                    if control.shape[0] > min([control_dict[keys][k].shape[0] for k in control_dict[keys].keys()]):\n",
    "                        control = control[:-1]\n",
    "                    # print(f\"control_key: {control_key}, control shape: {control.shape}\")\n",
    "                    control_list.append(control)\n",
    "                control = np.concatenate(control_list, axis=1)\n",
    "                action_list.append(control)\n",
    "            action = np.concatenate(action_list, axis=1)\n",
    "            state = copy.deepcopy(action)\n",
    "            \n",
    "            action = action[1:]\n",
    "            state = state[0:-1]\n",
    "            \n",
    "            # Process images and create GIFs for each camera\n",
    "            for sensor_type in image_dict.keys():\n",
    "                for key in image_dict[sensor_type].keys():\n",
    "                    image_dict[sensor_type][key] = image_dict[sensor_type][key][0:-1]\n",
    "                for cam_name in image_dict[sensor_type].keys():\n",
    "                    os.makedirs(os.path.join(save_dir, trajectory_id), exist_ok=True)\n",
    "                    gif_path = os.path.join(save_dir, trajectory_id, f'{cam_name}_{sensor_type}.gif')\n",
    "                    \n",
    "                    # Convert images to correct color format\n",
    "                    images = []\n",
    "                    for step in range(len(image_dict[sensor_type][cam_name])):\n",
    "                        img = np.array(image_dict[sensor_type][cam_name][step])\n",
    "                        # print(f\"cam_name: {cam_name}\")\n",
    "                        # print(img.shape)\n",
    "                        if sensor_type == 'rgb_images':\n",
    "                            # These embodiments image data are recorded in BGR\n",
    "                            if cur_embodiments in ['h5_franka_3rgb', 'h5_franka_1rgb', 'h5_ur_1rgb', 'h5_franka_fr3_dual']:\n",
    "                                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                            # Other embodiments image data are recorded in RGB  \n",
    "                            else:\n",
    "                                img = img\n",
    "                        elif sensor_type == 'depth_images':\n",
    "                            if img is not None:\n",
    "                                depth_gray = img\n",
    "                                # Normalize depth image to 0-255 range\n",
    "                                depth_min = np.min(depth_gray)\n",
    "                                depth_max = np.max(depth_gray)\n",
    "                                img = ((depth_gray - depth_min) / (depth_max - depth_min) * 255).astype(np.uint8)\n",
    "                                img = cv2.applyColorMap(img, cv2.COLORMAP_JET)\n",
    "                                # cv2.imwrite(os.path.join(save_dir, trajectory_id, f'{cam_name}_{sensor_type}_{step:04d}.png'), img)\n",
    "                            else:\n",
    "                                continue  # Skip if depth image is None\n",
    "\n",
    "\n",
    "                        img = cv2.resize(img, resolution, interpolation=cv2.INTER_AREA)\n",
    "                        images.append(img)\n",
    "                    \n",
    "                    imageio.mimsave(gif_path, images, duration=0.1)  # 10 FPS\n",
    "                    print(f\"Saved GIF to {gif_path}\")\n",
    "                    # Display the GIF in the notebook\n",
    "                    display(Image(filename=gif_path))\n",
    "    return \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(args):\n",
    "    env_name = args.env_name\n",
    "    if args.embodiments == \"h5_ur_1rgb\":\n",
    "        robot_infor = { \n",
    "            \"camera_names\": ['camera_top'], \n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['puppet'],\n",
    "            \"controls\": ['joint_position', 'end_effector'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"bread_in_basket_1\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_franka_3rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top', 'camera_left', 'camera_right'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['puppet'],\n",
    "            \"controls\": ['joint_position', 'end_effector'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"241021_close_trash_bin_1\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_franka_1rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['puppet'],\n",
    "            \"controls\": ['joint_position', 'end_effector'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"bread_on_table\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_tienkung_gello_1rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['puppet','master'],\n",
    "            \"controls\": ['joint_position'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"close_the_drawer_under_the_combination_cabinet\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_tienkung_xsens_1rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['puppet','master'],\n",
    "            \"controls\": ['joint_position', 'end_effector'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"place_button\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_agilex_3rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_front', 'camera_left_wrist', 'camera_right_wrist'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['puppet', 'master'],\n",
    "            \"controls\":  ['end_effector_left', 'end_effector_right', 'joint_effort_left', 'joint_effort_right', 'joint_position_left', 'joint_position_right', 'joint_velocity_left', 'joint_velocity_right'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"35_putcarrot\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_simulation\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\":  ['camera_front_external', 'camera_handeye', 'camera_left_external', 'camera_right_external'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['franka'],\n",
    "            \"controls\": ['end_effector', 'joint_effort', 'joint_position', 'joint_velocity'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"open_and_close_01\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_franka_fr3_dual\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top', 'camera_left', 'camera_right', 'camera_front'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['puppet'],\n",
    "            \"controls\": ['joint_position', 'end_effector'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"both_pour_water\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_sim_franka_3rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_front_external', 'camera_handeye', 'camera_left_external', 'camera_right_external'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['franka'],\n",
    "            \"controls\": ['end_effector', 'joint_effort', 'joint_position', 'joint_velocity'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"open_and_close_07\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_sim_tienkung_1rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_chest', 'camera_head'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['tiangong'],\n",
    "            \"controls\": ['left_arm_joint_effort_seqs', 'left_arm_joint_pos_seq', 'left_arm_joint_vel_seq', 'left_end_effector_waist', 'left_hand_joint_effort_seq', 'left_hand_joint_pos_seq', 'left_hand_joint_vel_seq',\n",
    "                         'right_arm_joint_effort_seq', 'right_arm_joint_pos_seq', 'right_arm_joint_vel_seq', 'right_end_effector_waist', 'right_hand_joint_pos_seq', 'right_hand_joint_vel_seq'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"pick_and_place_01_tienkung\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_tienkung_prod1_gello_1rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top'],\n",
    "            \"camera_sensors\": ['rgb_images', 'depth_images'],\n",
    "            \"arms\": ['puppet', 'master'],\n",
    "            \"controls\": ['joint_position'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"pick_up_foil_plate_place_in_dustbin\" if args.env_name is None else args.env_name\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid embodiment: {args.embodiments}\")\n",
    "    dataset_dir = os.path.join(args.dataset_path, args.embodiments)\n",
    "    cur_embodiments = args.embodiments\n",
    "    convert_dataset_image(cur_embodiments, robot_infor, resolution=RESOLUTION, dataset_dir=dataset_dir, env_names=[env_name], save_dir=args.save_dir,episode_num_pertask=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start \n",
    "Set `dataset_path` to the local RoboMIND directory and specify `embodiments`, `env_name` and `save_dir`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # ./data\n",
    "    parser.add_argument(\"--embodiments\", type=str, \n",
    "                     choices=[\n",
    "                        \"h5_franka_1rgb\", \"h5_franka_3rgb\", \"h5_tienkung_gello_1rgb\", \"h5_tienkung_xsens_1rgb\", \"h5_ur_1rgb\", \"h5_agilex_3rgb\", \"h5_simulation\",\n",
    "                        \"h5_franka_fr3_dual\", \"h5_sim_franka_3rgb\", \"h5_sim_tienkung_1rgb\", \"h5_tienkung_prod1_gello_1rgb\"],\n",
    "                     default=\"h5_franka_1rgb\",\n",
    "                     help=\"Choose the embodiment for data processing\")\n",
    "    parser.add_argument(\"--dataset_path\", type=str, default=\"./data\")\n",
    "    parser.add_argument(\"--env_name\", type=str, default=None)\n",
    "    parser.add_argument(\"--save_dir\", type=str, default=\"./save_dir\",)\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dataaug",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
