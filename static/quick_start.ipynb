{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install opencv-python\n",
    "!pip install h5py\n",
    "!pip install imageio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import argparse\n",
    "import imageio\n",
    "import h5py\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "from IPython.display import Image, display\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESOLUTION = (128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ReadH5Files():\n",
    "    def __init__(self, robot_infor):\n",
    "        self.camera_names = robot_infor['camera_names']\n",
    "        self.camera_sensors = robot_infor['camera_sensors']\n",
    "        self.arms = robot_infor['arms']\n",
    "        self.robot_infor = robot_infor['controls']\n",
    "\n",
    "    def decoder_image(self, camera_rgb_images, camera_depth_images):\n",
    "        if type(camera_rgb_images[0]) is np.uint8:\n",
    "            rgb = cv2.imdecode(camera_rgb_images, cv2.IMREAD_COLOR)\n",
    "            if camera_depth_images is not None:\n",
    "                depth_array = np.frombuffer(camera_depth_images, dtype=np.uint8)\n",
    "                depth = cv2.imdecode(depth_array, cv2.IMREAD_UNCHANGED)\n",
    "            else:\n",
    "                depth = np.asarray([])\n",
    "            return rgb, depth\n",
    "        else:\n",
    "            rgb_images = []\n",
    "            depth_images = []\n",
    "            for idx, camera_rgb_image in enumerate(camera_rgb_images):\n",
    "                camera_rgb_image = np.array(camera_rgb_image)\n",
    "                # print(f\"camera_rgb_image: {camera_rgb_image.shape}\")\n",
    "                rgb = cv2.imdecode(camera_rgb_image, cv2.IMREAD_COLOR)\n",
    "                if rgb is None:\n",
    "                    rgb = np.frombuffer(camera_rgb_image, dtype=np.uint8)\n",
    "                    rgb = rgb.reshape(720, 1280, 3)\n",
    "                if camera_depth_images is not None:\n",
    "                    depth_array = np.frombuffer(camera_depth_images[idx], dtype=np.uint8)\n",
    "                    depth = cv2.imdecode(depth_array, cv2.IMREAD_UNCHANGED)\n",
    "                else:\n",
    "                    depth = np.asarray([])\n",
    "                rgb_images.append(rgb)\n",
    "                depth_images.append(depth)\n",
    "            rgb_images = np.asarray(rgb_images)\n",
    "            depth_images = np.asarray(depth_images)\n",
    "            return rgb_images, depth_images\n",
    "\n",
    "    def execute(self, file_path, camera_frame=None, control_frame=None):\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            is_sim = f.attrs['sim']\n",
    "            is_compress = f.attrs['compress']\n",
    "            is_compress = True\n",
    "            image_dict = defaultdict(dict)\n",
    "            for cam_name in self.camera_names:\n",
    "                if is_compress:\n",
    "                    if camera_frame is not None:\n",
    "                        if len(self.camera_sensors) >= 2:\n",
    "                            decode_rgb, decode_depth = self.decoder_image(\n",
    "                                camera_rgb_images=f['observations'][self.camera_sensors[0]][cam_name][camera_frame],\n",
    "                                    camera_depth_images=f['observations'][self.camera_sensors[1]][cam_name][camera_frame])\n",
    "                        else:\n",
    "                            decode_rgb, decode_depth = self.decoder_image(\n",
    "                                camera_rgb_images=f['observations'][self.camera_sensors[0]][cam_name][camera_frame],\n",
    "                                camera_depth_images=None)\n",
    "                    else:\n",
    "                        if len(self.camera_sensors) >= 2:\n",
    "                            rgb_images = f['observations'][self.camera_sensors[0]][cam_name][:]\n",
    "                            depth_images = f['observations'][self.camera_sensors[1]][cam_name][:]\n",
    "                        else:\n",
    "                            rgb_images = f['observations'][self.camera_sensors[0]][cam_name][:]\n",
    "                            depth_images = None\n",
    "                        print(f\"rgb_images: {rgb_images.shape}\")\n",
    "                        decode_rgb, decode_depth = self.decoder_image(camera_rgb_images=rgb_images,camera_depth_images=depth_images)\n",
    "                    \n",
    "                    image_dict[self.camera_sensors[0]][cam_name] = decode_rgb\n",
    "                    if len(self.camera_sensors) >= 2:\n",
    "                        image_dict[self.camera_sensors[1]][cam_name] = decode_depth\n",
    "\n",
    "                else:\n",
    "                    if camera_frame:\n",
    "                        image_dict[self.camera_sensors[0]][cam_name] = f[\n",
    "                            'observations'][self.camera_sensors[0]][cam_name][camera_frame]\n",
    "                        image_dict[self.camera_sensors[1]][cam_name] = f[\n",
    "                            'observations'][self.camera_sensors[1]][cam_name][camera_frame]\n",
    "                    else:\n",
    "                        image_dict[self.camera_sensors[0]][cam_name] = f[\n",
    "                           'observations'][self.camera_sensors[0]][cam_name][:]\n",
    "\n",
    "\n",
    "            control_dict = defaultdict(dict)\n",
    "            for arm_name in self.arms:\n",
    "                for control in self.robot_infor:\n",
    "                    if control_frame:\n",
    "                        control_dict[arm_name][control] = f[arm_name][control][control_frame]\n",
    "                    else:\n",
    "                        control_dict[arm_name][control] = f[arm_name][control][:]\n",
    "            base_dict = defaultdict(dict)\n",
    "        return image_dict[self.camera_sensors[0]], control_dict, base_dict, is_sim, is_compress\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_dataset_image(cur_embodiments, robot_infor, resolution=RESOLUTION, dataset_dir=\"realworld_data\", env_names=None, episode_num_pertask=2):\n",
    "    read_h5files = ReadH5Files(robot_infor)\n",
    "\n",
    "    for env_name in env_names:\n",
    "        save_dir = f'quick_start_saved_images/{env_name}'\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        dataset_root = os.path.join(dataset_dir, env_name, 'success_episodes/train')\n",
    "        cnt = 0\n",
    "        for trajectory_id in sorted(os.listdir(dataset_root))[0:episode_num_pertask]:\n",
    "            for file in os.listdir(os.path.join(dataset_root, trajectory_id, 'data')):\n",
    "                if file.endswith('.hdf5'):\n",
    "                    file_path = os.path.join(dataset_root, trajectory_id, 'data', file)\n",
    "                    break\n",
    "            print('executing ', cnt, 'th trajectory, file_path:', file_path)\n",
    "            cnt += 1\n",
    "            assert os.path.exists(file_path), f'{file_path} does not exist'\n",
    "            image_dict, control_dict, base_dict, _, is_compress = read_h5files.execute(file_path)\n",
    "            action_list = []\n",
    "            for keys in control_dict.keys():\n",
    "                control_list = []\n",
    "                for control_key in control_dict[keys].keys():\n",
    "                    control = control_dict[keys][control_key]\n",
    "                    control_list.append(control)\n",
    "                control = np.concatenate(control_list, axis=1)\n",
    "                action_list.append(control)\n",
    "            action = np.concatenate(action_list, axis=1)\n",
    "            state = copy.deepcopy(action)\n",
    "            \n",
    "            action = action[1:]\n",
    "            state = state[0:-1]\n",
    "            for key in image_dict.keys():\n",
    "                image_dict[key] = image_dict[key][0:-1]\n",
    "            \n",
    "            # Process images and create GIFs for each camera\n",
    "            for cam_name in image_dict.keys():\n",
    "                os.makedirs(os.path.join(save_dir, trajectory_id), exist_ok=True)\n",
    "                gif_path = os.path.join(save_dir, trajectory_id, f'{cam_name}.gif')\n",
    "                \n",
    "                # Convert images to correct color format\n",
    "                images = []\n",
    "                for step in range(len(image_dict[cam_name])):\n",
    "                    img = np.array(image_dict[cam_name][step])\n",
    "                    # print(f\"cam_name: {cam_name}\")\n",
    "                    # print(img.shape)\n",
    "                    # Convert BGR to RGB if necessary\n",
    "                    if img.shape[-1] == 3:  # Check if image has 3 channels\n",
    "                        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    if cur_embodiments not in ['h5_franka_3rgb', 'h5_franka_1rgb', 'h5_ur_1rgb']:\n",
    "                        img = img[:, :, ::-1]\n",
    "                    \n",
    "                    img = cv2.resize(img, resolution, interpolation=cv2.INTER_AREA)\n",
    "                    images.append(img)\n",
    "                \n",
    "                imageio.mimsave(gif_path, images, duration=0.1)  # 10 FPS\n",
    "                print(f\"Saved GIF to {gif_path}\")\n",
    "                # Display the GIF in the notebook\n",
    "                display(Image(filename=gif_path))\n",
    "            return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main(args):\n",
    "    env_name = args.env_name\n",
    "    if args.embodiments == \"h5_ur_1rgb\":\n",
    "        robot_infor = { \n",
    "            \"camera_names\": ['camera_top'], \n",
    "            \"camera_sensors\": ['rgb_images'],\n",
    "            \"arms\": ['puppet'],\n",
    "            \"controls\": ['joint_position', 'end_effector'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"close_top_drawer\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_franka_3rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top', 'camera_left', 'camera_right'],\n",
    "            \"camera_sensors\": ['rgb_images'],\n",
    "            \"arms\": ['puppet'],\n",
    "            \"controls\": ['joint_position', 'end_effector'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"241021_close_trash_bin_1\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_franka_1rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top'],\n",
    "            \"camera_sensors\": ['rgb_images'],\n",
    "            \"arms\": ['puppet'],\n",
    "            \"controls\": ['joint_position', 'end_effector'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"bread_on_table\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_tienkung_gello_1rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top'],\n",
    "            \"camera_sensors\": ['rgb_images'],\n",
    "            \"arms\": ['puppet','master'],\n",
    "            \"controls\": ['joint_position'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"close_the_drawer_under_the_combination_cabinet\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_tienkung_xsens_1rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_top'],\n",
    "            \"camera_sensors\": ['rgb_images'],\n",
    "            \"arms\": ['puppet','master'],\n",
    "            \"controls\": ['joint_position', 'end_effector'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"place_button\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_agilex_3rgb\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\": ['camera_front', 'camera_left_wrist', 'camera_right_wrist'],\n",
    "            \"camera_sensors\": ['rgb_images'],\n",
    "            \"arms\": ['puppet', 'master'],\n",
    "            \"controls\":  ['end_effector_left', 'end_effector_right', 'joint_effort_left', 'joint_effort_right', 'joint_position_left', 'joint_position_right', 'joint_velocity_left', 'joint_velocity_right'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"35_putcarrot\" if args.env_name is None else args.env_name\n",
    "    elif args.embodiments == \"h5_simulation\":\n",
    "        robot_infor = {\n",
    "            \"camera_names\":  ['camera_front_external', 'camera_handeye', 'camera_left_external', 'camera_right_external'],\n",
    "            \"camera_sensors\": ['rgb_images'],\n",
    "            \"arms\": ['franka'],\n",
    "            \"controls\": ['end_effector', 'joint_effort', 'joint_position', 'joint_velocity'],\n",
    "            \"resolution\": RESOLUTION\n",
    "        }\n",
    "        env_name = \"open_and_close_01\" if args.env_name is None else args.env_name\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid embodiment: {args.embodiments}\")\n",
    "    dataset_dir = os.path.join(args.dataset_path, args.embodiments)\n",
    "    cur_embodiments = args.embodiments\n",
    "    convert_dataset_image(cur_embodiments, robot_infor, resolution=RESOLUTION, dataset_dir=dataset_dir, env_names=[env_name], episode_num_pertask=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Start \n",
    "Set `dataset_path` to the local RoboMIND directory and specify `embodiments` and `env_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # ./data\n",
    "    parser.add_argument(\"--embodiments\", type=str, \n",
    "                     choices=[\"h5_franka_1rgb\", \"h5_franka_3rgb\", \"h5_tienkung_gello_1rgb\", \"h5_tienkung_xsens_1rgb\", \"h5_ur_1rgb\", \"h5_agilex_3rgb\", \"h5_simulation\"],\n",
    "                     default=\"h5_ur_1rgb\",\n",
    "                     help=\"Choose the embodiment for data processing\")\n",
    "    parser.add_argument(\"--dataset_path\", type=str, default=\"./data\")\n",
    "    parser.add_argument(\"--env_name\", type=str, default=None)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # args = parser.parse_args([\n",
    "    #     '--embodiments', 'h5_tienkung_xsens_1rgb',\n",
    "    #     '--dataset_path', './data',\n",
    "    #     '--env_name', 'close_the_drawer_under_the_combination_cabinet'\n",
    "    # ])\n",
    "\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
